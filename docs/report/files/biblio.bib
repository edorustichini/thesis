@online{JPEG106thMeeting,
  title = {{{JPEG}} - 106th {{Meeting}} – {{Online}} - {{JPEG AI}} Becomes an {{International Standard}}},
  url = {https://jpeg.org/items/20250219_press.html},
  urldate = {2025-08-22},
}

@article{jpeg,
  title={The JPEG still picture compression standard},
  author={Wallace, Gregory K},
  journal={Communications of the ACM},
  volume={34},
  number={4},
  pages={30--44},
  year={1991},
  publisher={AcM New York, NY, USA}
}

@article{ascenso2023jpegAI,
  title={The JPEG AI standard: Providing efficient human and machine visual data consumption},
  author={Ascenso, Jo{\~a}o and Alshina, Elena and Ebrahimi, Touradj},
  journal={Ieee Multimedia},
  volume={30},
  number={1},
  pages={100--111},
  year={2023},
  publisher={IEEE}
}

@article{ascenso2019performance,
  title={Performance evaluation of learning based image coding solutions and quality metrics},
  author={Ascenso, J and Akayzi, P and Testolina, M and Boev, A and Alshina, E},
  journal={ISO/IEC JTC},
  volume={1},
  year={2019}
}

@inproceedings{sonehara1989image,
  title={Image data compression using a neural network model},
  author={Sonehara and Kawato and Miyake and Nakane},
  booktitle={International 1989 Joint Conference on Neural Networks},
  pages={35--41},
  year={1989},
  organization={IEEE}
}
@article{sicuranza1990artificial,
  title={Artificial neural network for image compression},
  author={Sicuranza, GL and Ramponi, GIOVANNI and Marsi, Stefano},
  journal={Electronics letters},
  volume={26},
  number={7},
  pages={477--479},
  year={1990},
  publisher={IET}
}

@article{balle2018variational,
  title={Variational image compression with a scale hyperprior},
  author={Ball{\'e}, Johannes and Minnen, David and Singh, Saurabh and Hwang, Sung Jin and Johnston, Nick},
  year={2018}
}

@article{minnen2018joint,
  title={Joint autoregressive and hierarchical priors for learned image compression},
  author={Minnen, David and Ball{\'e}, Johannes and Toderici, George D},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{huang2024unveiling,
  title={Unveiling the future of human and machine coding: A survey of end-to-end learned image compression},
  author={Huang, Chen-Hsiu and Wu, Ja-Ling},
  journal={Entropy},
  volume={26},
  number={5},
  pages={357},
  year={2024},
  publisher={MDPI}
}
@article{mishra2022deep,
  title={Deep architectures for image compression: a critical review},
  author={Mishra, Dipti and Singh, Satish Kumar and Singh, Rajat Kumar},
  journal={Signal Processing},
  volume={191},
  pages={108346},
  year={2022},
  publisher={Elsevier}
}
@article{theis2017lossy,
  title={Lossy image compression with compressive autoencoders},
  author={Theis, Lucas and Shi, Wenzhe and Cunningham, Andrew and Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:1703.00395},
  year={2017}
}

@article{ascenso2019report,
  title={Report on the state-of-the-art of learning based image coding},
  author={Ascenso, J and Akayzi, P},
  journal={ISO/IEC JTC 1/SC29/WG1, Geneva, Document N83058},
  year={2019}
}
@article{zhang2025unmasking,
  title={Unmasking AI-Created Visual Content: A Review of Generated Images and Deepfake Detection Technologies},
  author={Zhang, Yupeng and Pang, Zongwei and Huang, Shanyuan and Wang, Chengyou and Zhou, Xiao},
  year={2025},
  publisher={Preprints}
}
@misc{jpeg-ai-ref-sw,
  title = {{{JPEG}} / {{JPEG AI}} / {{JPEG AI Reference Software}} {$\cdot$} {{GitLab}}},
  year = {2025},
  month = jul,
  journal = {GitLab},
  urldate = {2025-08-25},
  abstract = {GitLab.com},
  howpublished = {https://gitlab.com/wg1/jpeg-ai/jpeg-ai-reference-software},
  langid = {english},
  file = {/home/edo/Zotero/storage/4N35BCSA/2025 - JPEG _ JPEG AI _ JPEG AI Reference Software · GitL.html}
}

@misc{NVlabsFfhqdataset2025,
  title = {{{NVlabs}}/Ffhq-Dataset},
  year = {2025},
  month = aug,
  urldate = {2025-08-25},
  abstract = {Flickr-Faces-HQ Dataset (FFHQ)},
  howpublished = {NVIDIA Research Projects}
}

@misc{140kRealFake,
  title = {140k {{Real}} and {{Fake Faces}}},
  urldate = {2025-08-25},
  abstract = {70k real faces (from Flickr) and 70k fake faces (GAN-generated)},
  howpublished = {https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces},
  langid = {english},
  file = {/home/edo/Zotero/storage/4P4EBNEU/140k-real-and-fake-faces.html}
}
@inproceedings{ccs,
  title={Learning-based conditional image coder using color separation},
  author={Jia, Panqi and Koyuncu, Ahmet Burakhan and Gaikov, Georgii and Karabutov, Alexander and Alshina, Elena and Kaup, Andr{\'e}},
  booktitle={2022 Picture Coding Symposium (PCS)},
  pages={49--53},
  year={2022},
  organization={IEEE}
}

@article{tolosana2020deepfakes,
  title={Deepfakes and beyond: A survey of face manipulation and fake detection},
  author={Tolosana, Ruben and Vera-Rodriguez, Ruben and Fierrez, Julian and Morales, Aythami and Ortega-Garcia, Javier},
  journal={Information Fusion},
  volume={64},
  pages={131--148},
  year={2020},
  publisher={Elsevier}
}
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{fernando2025face,
  title={Face Deepfakes--A Comprehensive Review},
  author={Fernando, Tharindu and Priyasad, Darshana and Sridharan, Sridha and Ross, Arun and Fookes, Clinton},
  year={2025}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{goodfellow2016nips,
  title={Nips 2016 tutorial: Generative adversarial networks},
  author={Goodfellow, Ian},
  journal={arXiv preprint arXiv:1701.00160},
  year={2016}
}

@misc{karras2019style,
      title={A Style-Based Generator Architecture for Generative Adversarial Networks}, 
      author={Tero Karras and Samuli Laine and Timo Aila},
      year={2019},
      eprint={1812.04948},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1812.04948}, 
}

@article{verdoliva2020media,
  title={Media forensics and deepfakes: an overview},
  author={Verdoliva, Luisa},
  journal={IEEE journal of selected topics in signal processing},
  volume={14},
  number={5},
  pages={910--932},
  year={2020},
  publisher={IEEE}
}
@misc{wang2023gangeneratedfacesdetectionsurvey,
      title={GAN-generated Faces Detection: A Survey and New Perspectives}, 
      author={Xin Wang and Hui Guo and Shu Hu and Ming-Ching Chang and Siwei Lyu},
      year={2023},
      eprint={2202.07145},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2202.07145}, 
}

@inproceedings{hofer2024taxonomy,
  title={A Taxonomy of Miscompressions: Preparing Image Forensics for Neural Compression},
  author={Hofer, Nora and B{\"o}hme, Rainer},
  booktitle={2024 IEEE International Workshop on Information Forensics and Security (WIFS)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@article{cannas2024jpeg,
  title={Is JPEG AI going to change image forensics?},
  author={Cannas, Edoardo Daniele and Mandelli, Sara and Popovi{\'c}, Nata{\v{s}}a and Alkhateeb, Ayman and Gnutti, Alessandro and Bestagini, Paolo and Tubaro, Stefano},
  journal={arXiv preprint arXiv:2412.03261},
  year={2024}
}

@article{bergmann2025three,
  title={Three Forensic Cues for JPEG AI Images},
  author={Bergmann, Sandra and Brand, Fabian and Riess, Christian},
  journal={arXiv preprint arXiv:2504.03191},
  year={2025}
}

@INPROCEEDINGS{7780459,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90}}

  @InProceedings{pmlr-v97-tan19a,
  title = 	 {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author =       {Tan, Mingxing and Le, Quoc},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6105--6114},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/tan19a.html},
  abstract = 	 {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.}
}

@INPROCEEDINGS{8099678,
  author={Chollet, François},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Xception: Deep Learning with Depthwise Separable Convolutions}, 
  year={2017},
  volume={},
  number={},
  pages={1800-1807},
  keywords={Computer architecture;Correlation;Convolutional codes;Google;Biological neural networks},
  doi={10.1109/CVPR.2017.195}}

@inproceedings{khodabakhsh2018fake,
  title={Fake face detection methods: Can they be generalized?},
  author={Khodabakhsh, Ali and Ramachandra, Raghavendra and Raja, Kiran and Wasnik, Pankaj and Busch, Christoph},
  booktitle={2018 international conference of the biometrics special interest group (BIOSIG)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{wang2023dire,
  title={Dire for diffusion-generated image detection},
  author={Wang, Zhendong and Bao, Jianmin and Zhou, Wengang and Wang, Weilun and Hu, Hezhen and Chen, Hong and Li, Houqiang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22445--22455},
  year={2023}
}
@techreport{wg1n100279,
  title = {Description of the {{JPEG AI}} Verification Model under Consideration and Associated Software Integration Procedure},
  author = {{ICQ}},
  year = {2022},
  number = {wg1n100279},
  institution = {ISO/IEC JTC 1/SC 29/WG 1}
}

@INPROCEEDINGS{10018070,
  author={Jia, Panqi and Koyuncu, Ahmet Burakhan and Gaikov, Georgii and Karabutov, Alexander and Alshina, Elena and Kaup, André},
  booktitle={2022 Picture Coding Symposium (PCS)}, 
  title={Learning-Based Conditional Image Coder Using Color Separation}, 
  year={2022},
  volume={},
  number={},
  pages={49-53},
  keywords={Codecs;Image coding;Image color analysis;Memory management;Graphics processing units;Artificial neural networks;Parallel processing;Learned Image Compression;Conditional Autoencoder;Deep Learning;Subsampled Color Space Coding;Complexity Reduction},
  doi={10.1109/PCS56426.2022.10018070}
  }

@misc{dolhansky2020deepfakedetectionchallengedfdc,
      title={The DeepFake Detection Challenge (DFDC) Dataset}, 
      author={Brian Dolhansky and Joanna Bitton and Ben Pflaum and Jikuo Lu and Russ Howes and Menglin Wang and Cristian Canton Ferrer},
      year={2020},
      eprint={2006.07397},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2006.07397}, 
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}